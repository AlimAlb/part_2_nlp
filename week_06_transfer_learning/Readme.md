## Материалы модуля 6

<div align="center">
  <img src="../images/dls.png">
</div>

### Предобучение и дообучение языковых моделей.

В этом модуле мы подробнее поговорим о современных методах предобучения языковых моделей, а также научимся файнтьюнить языковые модели для решения прикладных задач NLP


### Лекция

В этом видео мы поговорим о Transfer Learning в задачах обработки естественного языка. 

Занятие ведёт Антон Земеров

### Семинар
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DeepLearningSchool/part_2_nlp/blob/main/week_06_transfer_learning/Practice/bart_finetuning_practice.ipynb)


В семинаре мы решим задачу суммаризации текста с помощью дообучения seq2seq-модели BART. 

Занятие ведёт Антон Земеров

### Домашнее задание

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/DeepLearningSchool/part_2_nlp/blob/main/week_06_transfer_learning/Homework/[homework]Attention_and_transformers.ipynb)

В этом домашнем задании вам предстоит решить задачу классификации математических задач по темам. 


